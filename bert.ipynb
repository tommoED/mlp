{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: NLP - English scheduling phrases to Machine Readable format\n",
    "\n",
    "Convert natural input:\n",
    "\n",
    "`every tues 3-4pm MLP Tutorial`\n",
    "\n",
    "to ics formatted string:\n",
    "\n",
    "```icalendar\n",
    "BEGIN:VCALENDAR\n",
    "VERSION:2.0\n",
    "PRODID:-//mlp.ed.ac.uk//group1//EN\n",
    "CALSCALE:GREGORIAN\n",
    "METHOD:PUBLISH\n",
    "BEGIN:VEVENT\n",
    "SUMMARY:MLP Tutorial\n",
    "UID:c7614cff-3549-4a00-9152-d25cc1fe077d\n",
    "SEQUENCE:0\n",
    "RRULE:FREQ=WEEKLY;BYDAY=TU;COUNT=10\n",
    "DTSTART:20250214T150000\n",
    "DTEND:20250214T160000\n",
    "DTSTAMP:20150421T150000\n",
    "CATEGORIES:University\n",
    "END:VEVENT\n",
    "END:VCALENDAR\n",
    "```\n",
    "\n",
    "## Goals\n",
    "- Deal with as many edge cases as possible\n",
    "- Deal with abbreviations\n",
    "- Deal with relative dates\n",
    "- Handle complex expressions as accurately as possible like from `2pm hourly til 5 every weekday for 5m except 3pm`\n",
    "\n",
    "\n",
    "\n",
    "## Strategy\n",
    "\n",
    "1. Use a base model BERT to use\n",
    "2. Use the TempEval-3.0 dataset to train a model to recognise the temporal expressions and extract the temporal relations.\n",
    "3. Use additional temporal reasoning datasets to increase the model reasoning performance.\n",
    "4. Use Evol-Instruct to augment and customise the datasets to increase variety, relevance and complexity of expressions.\n",
    "\n",
    "![Evol-Instruct workflow](evol.png)\n",
    "\n",
    "\n",
    "\n",
    "## Base models\n",
    "\n",
    "\n",
    "### BERT\n",
    "\n",
    "### [BERTweet](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/bertweet)\n",
    "- Pre-trained on 850M English tweets\n",
    "- Better at handling informal language, emojis, hashtags, mobile input\n",
    "- May be more suitable for processing colloquial text and abbreviations\n",
    "\n",
    "### [DateBERT](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/datebert)\n",
    "- Tags dates and times in text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Embeddings\n",
    "\n",
    "### Contextual Embeddings\n",
    "- Reference date\n",
    "- Region / timezone\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "tokeniser = Tokenizer(BPE())\n",
    "tokeniser.pre_tokenizer = Whitespace()\n",
    "\n",
    "trainer = BpeTrainer(vocab_size=120, special_tokens=[\"<pad>\", \"</s>\"])\n",
    "tokeniser.train(files=[\"phrases.txt\"], trainer=trainer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12', '/', '0', '6', 'm', 'a', 'ch', 'in', 'e', 'l', 'e', 'ar', 'ning', 'tu', 't', 'or', 'i', 'al', 'in', 'A', 'T', '4', '.', '12'] 24\n"
     ]
    }
   ],
   "source": [
    "with open('subset.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    # remove duplicates\n",
    "    lines = list(set(lines))\n",
    "    \n",
    "tokenised_lines = [tokeniser.encode(line.strip()) for line in lines]\n",
    "\n",
    "longest_line = max(tokenised_lines, key=len)\n",
    "\n",
    "print(longest_line.tokens, len(longest_line.tokens))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 40 most frequent tokens:\n",
      "end: 159\n",
      "ss: 158\n",
      "og: 157\n",
      "ner: 156\n",
      "mar: 155\n",
      "last: 154\n",
      "it: 153\n",
      "din: 152\n",
      "age: 151\n",
      "6pm: 150\n",
      "meeting: 149\n",
      "shop: 148\n",
      "meet: 147\n",
      "int: 146\n",
      "team: 145\n",
      "sho: 144\n",
      "ning: 143\n",
      "mo: 142\n",
      "eam: 141\n",
      "da: 140\n",
      "5hrs: 139\n",
      "5pm: 138\n",
      "3hrs: 137\n",
      "session: 136\n",
      "view: 135\n",
      "rep: 134\n",
      "up: 133\n",
      "sess: 132\n",
      "lan: 131\n",
      "12pm: 130\n",
      "11am: 129\n",
      "ation: 128\n",
      "30pm: 127\n",
      "remind: 126\n",
      "ge: 125\n",
      "ast: 124\n",
      "45: 123\n",
      "00: 122\n",
      "10am: 121\n",
      "art: 120\n"
     ]
    }
   ],
   "source": [
    "# Get all tokens and their frequencies from the tokenizer\n",
    "vocab = tokeniser.get_vocab()\n",
    "sorted_vocab = sorted(vocab.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Calculate number of tokens in top quartile\n",
    "num_tokens = len(sorted_vocab)\n",
    "quartile_size = num_tokens // 4\n",
    "\n",
    "# Get top quartile tokens\n",
    "top_quartile = sorted_vocab[:quartile_size]\n",
    "\n",
    "print(f\"Top {quartile_size} most frequent tokens:\")\n",
    "for token, freq in top_quartile:\n",
    "    print(f\"{token}: {freq}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
